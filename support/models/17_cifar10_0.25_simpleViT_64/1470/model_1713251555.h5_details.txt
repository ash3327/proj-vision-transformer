SimpleViT(
  (to_patch_embedding): Sequential(
    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)
    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (2): Linear(in_features=192, out_features=500, bias=True)
    (3): LayerNorm((500,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (norm): LayerNorm((500,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0-15): 16 x ModuleList(
        (0): Attention(
          (norm): LayerNorm((500,), eps=1e-05, elementwise_affine=True)
          (attend): Softmax(dim=-1)
          (to_qkv): Linear(in_features=500, out_features=1536, bias=False)
          (to_out): Linear(in_features=512, out_features=500, bias=False)
        )
        (1): FeedForward(
          (net): Sequential(
            (0): LayerNorm((500,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=500, out_features=500, bias=True)
            (2): GELU(approximate='none')
            (3): Linear(in_features=500, out_features=500, bias=True)
          )
        )
      )
    )
  )
  (to_latent): Identity()
  (linear_head): Linear(in_features=500, out_features=10, bias=True)
)
 Train accuracy: 25.0%, Avg loss: 0.000000, lr: 8.000000000000004e-09
 Test accuracy: 50.1%, Avg loss: 5.837708
